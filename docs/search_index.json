[
["index.html", "Data visualisation using R, for researchers who don’t use R Overview", " Data visualisation using R, for researchers who don’t use R Emily Nordmann, Phil McAleer, Wilhelmiina Toivo, Helena Paterson, Lisa DeBruine 2021-06-07 Overview Please cite this book as: "],
["introduction.html", "Chapter 1 Introduction 1.1 Why R for data visualisation? 1.2 A layered grammar of graphics 1.3 Simulated dataset 1.4 Setting up R and RStudio 1.5 Preparing your data", " Chapter 1 Introduction Use of the programming language R for data processing and statistical analysis by researchers is increasingly common with a GET THE STATS FROM THAT THING I SAW ABOUT R ON TWITTER rise since XXXX (REF). In addition to benefiting reproducibility and transparency, one of the advantages of using R is that researchers have a much larger range of fully customisable data visualisations options than are typically available in point-and-click software, due to the open-source nature of R. These visualisation options not only look attractive, but can increase transparency about the distribution of the underlying data rather than relying on commonly used visualisations of aggregations such as bar charts of means (Newman and Scholl 2012). Yet, the benefits of using R are obscured for many researchers by the perception that coding skills are difficult to learn (Robins, Rountree, and Rountree 2003). Coupled with this, only a minority of psychology programmes currently teach coding skills (Wills, n.d.) with the majority of both undergraduate and postgraduate courses using proprietary and point-and-click software such as SAS, SPSS or Microsoft Excel. While the sophisticated use of proprietary software often necessitates the use of computational thinking skills akin to coding (for instance SPSS scripts or formulas in Excel), we have found that many researchers do not perceive that they already have introductory coding skills. In the following tutorial we intend to change that perception by showing how experienced researchers can redevelop their existing computational skills to utilise the powerful data visualisation tools offered by R. We aim to provide a practical introduction to data visualisation using R, specifically aimed at researchers who have little to no prior experience using R. We detail the rationale for using R for data visualisation, introduce the “grammar of graphics” that underlies data visualisation using the ggplot package, and provide a tutorial that walks the reader through how to replicate plots that are commonly available in point-and-click software such as histograms and boxplots, as well as showing how the code for these “basic” plots can be easily extended to less commonly available options such as violin-boxplots, raincloud plots, and heat-maps. 1.1 Why R for data visualisation? Data visualisation benefits from the same advantages as statistical analysis when writing code rather than using point-and-click software – reproducibility and transparency. The need for psychological researchers to work in reproducible ways has been well-documented and discussed in response to the replication crisis (e.g. Munafò et al. 2017) and we will not repeat those arguments here. However, there is an additional benefit to reproducibility that is less frequently acknowledged compared to the loftier goals of improving psychological science: if you write code to produce your plots, future-you can reuse and adapt that code rather than starting from scratch each time. In addition to the benefits of reproducibility, using R for data visualisation gives the researcher almost total control over each element of the plot. Whilst this flexibility can seem daunting at first, the ability to write reusable code recipes (and use recipes created by others) is highly advantageous. The level of customisation and the professional outputs available using R has for instance lead news outlets such as the BBC (Visual and Journalism 2019) and the New York Times (Bertini and Stefaner 2015) adopting R as their preferred data visualisation tool. 1.2 A layered grammar of graphics There are multiple approaches to data visualisation in R; in this paper we will be using the popular package1 ggplot2 (Wickham 2016) which is part of the larger tidyverse2 (Wickham 2017) collection of packages that provide functions for data wrangling, descriptives, and visualisation. A grammar of graphics (Wilkinson, Anand, and Grossman 2005) is a standardised way to describe the components of a graphic. ggplot2 uses a layered grammar of graphics (Wickham 2010), in which plots are built up in a series of layers. It may be helpful to think about any picture as having multiple elements that sit semi-transparently over each other. A good analogy is old Disney movies where artists would create a background and then add moveable elements on top of the background via transparencies. Figure 1.1 displays the evolution of a simple scatterplot using this layered approach. First, the plot space is built (layer 1); the variables are specified (layer 2); the type of visualisation (known as a geom) that is desired for these variables is specified (layer 3) - in this case geom_point() is called to visualise individual data points; a second geom is added to include a line of best fit (layer 4), the axis labels are edited for readability (layer 5), and finally, a theme is applied to change the overall appearance of the plot (layer 6). Figure 1.1: Evolution of a layered plot Importantly, each layer is independent and independently customisable. For example, the size, colour and position of each component can be adjusted, or one could, for example, remove the first geom (geometric object) to only visualise the line of best fit, simply by removing the layer that draws the data points (Figure 1.2). The use of layers makes it easy to build up complex plots step-by-step, and to adapt or extend plots from existing code. Figure 1.2: Plot with scatterplot layer removed. 1.3 Simulated dataset For the purpose of this tutorial, we will use simulated data for a 2 x 2 mixed-design lexical decision task. There are 100 rows (1 for each subject) and 7 variables: Participant information: id: Participant ID age: Age 1 between-subject IV: language: Language group (1 = monolingual/2 = bilingual) 4 columns for the 2 dependent variables for RT and accuracy, crossed by the within-subject IV of condition: rt_word`: Reaction time (ms) for word trials rt_nonword`: Reaction time (ms) for non-word trials acc_word: Accuracy for word trials acc_nonword: Accuracy for non-word trials The simulated dataset and tutorial code can be found in the online supplementary materials. For newcomers to R, we would suggest working through this tutorial with the simulated dataset, then extending the code to your own datasets with a similar structure, and finally generalising the code to new structures and problems. 1.4 Setting up R and RStudio We strongly encourage the use of RStudio to write code in R. R is the programming language whilst RStudio is an integrated development environment that makes working with R easier. More information on installing both R and RStudio can be found in the additional resources. Projects are a useful way of keeping all your code, data, and output in one place. To create a new project, open RStudio and click File - New Project - New Directory - New Project. You will be prompted to give the project a name, and select a location for where to store the project on your computer. Once you have done this, click Create Project. Download the simulated dataset from the online materials and save the file ( ldt_data.csv) to this folder. The files pane on the bottom right of RStudio should now display this folder and the files it contains - this is known as your working directory and it is where R will look for any data you wish to import and where it will save any output you create. This tutorial will require you to use the packages contained with the tidyverse collection. Additionally, we will also require use of patchwork. To install these packages, copy and paste the below code into the console (the left hand pane) and press enter to execute the code. # only run in the console, never put this in a script package_list &lt;- c(&quot;tidyverse&quot;, &quot;patchwork&quot;) install.packages(package_list) Finally, so that you can save your code to return to later, open a new script File - New File - R Script and then save it using File - Save. R will default to saving the script in your project folder. This is where we will write all the tutorial code from now on. We have also provided an R Markdown copy of all below code in the supplementary materials. The reason that the install packages code is not included in the script is that every time you run the install command code it will install the latest version of the package and so leaving this code in your script can lead you to unintentionally install a package update you didn’t want. For this reason, avoid including install code in any script. R scripts (or R code chunks if you are using Markdown) treat anything you write in them as code by default. If you wish to write a comment with further information about your code (which we encourage you to do), you must use the hashtag sign to “comment it out.” There is more information about the difference between scripts and Markdown documents in the additional resources. this_is_code # this is a comment 1.5 Preparing your data Before you start visualizing your data, you need to get it into an appropriate format. These preparatory steps can all be dealt with reproducibly using R and the additional resources section points to extra tutorials for doing so. However, performing these types of tasks in R can require more sophisticated coding skills and the solutions and tools are dependent on the idiosyncrasies of each dataset. For this reason, in this tutorial we encourage the reader to complete data preparation steps using the method they are most comfortable with and to focus on the aim of data visualisation. 1.5.1 Data format The simulated lexical decision data is provided in a csv file rather than e.g., xslx. Functions exist in R to read many other types of data files, however, we recommend that you convert any xlsx spreadsheets to csv by using the Save As function in Microsoft Excel. The csv file format strips all formatting and only stores data in a single sheet and so is simpler for new users to import to R. You may wish to create a csv file that contains only the data you want to visualise, rather than a full, larger workbook. When working with your own data, any files you import should remove summary rows or additional notes and should only contains the rows and columns of data you want to plot. 1.5.2 Variable names Ensuring that your variable names are consistent can make it much easier to work in R. We recommend using short but informative variable names, for example rt_word is preferred over dv1_iv1 or reaction_time_word_condition because these are either hard to read or hard to type. It is also helpful to have a consistent naming scheme, particularly for variable names that require more than one word. Two popular options are CamelCase where each new word begins with a capital letter, or snake_case where all letters are lower case and words are separated by an underscore. For the purposes of naming variables, avoid using any spaces in variable names (e.g., rt word) and consider the additional meaning of a separator beyond making the variable names easier to read. For example, rt_word, rt_nonword, acc_word, and acc_nonword all have the DV to the left of the separator and the level of the IV to the right. rt_word_condition on the other hand has two separators but only one of them is meaningful and it is useful to be able to split variable names consistently. In this paper, we will use snake_case and lower case letters for all variable names so that we don’t have to remember where to put the capital letters. When working with your own data, you can rename columns in Excel, but there are also instructions for how to do this in R in the additional resources. 1.5.3 Data values A great benefit to using R rather than SPSS is that categorical data can be entered as text. In the tutorial dataset, language group is entered as 1 or 2, so that we can show you how to recode numeric values into factors with labels. However, we recommend recording meaningful labels rather than numbers from the beginning of data collection to avoid misinterpreting data due to coding errors. Note that values must match exactly in order to be considered in the same category and R is case sensitive, so “mono,” “Mono,” and “monolingual” would be classified as members of three separate categories. Finally, cells that represent missing data should be left empty rather than containing values like NA, missing or 0. A complementary rule of thumb is that each column should only contain one type of data, such as words or numbers, not both. The power of R is that it is extendable and open source - put simply, if a function doesn’t exist or is difficult to use, anyone can create a new package that contains data and code to allow you to perform new tasks. You may find it helpful to think of packages as additional apps that you need to download separately to extend the functionality beyond what comes with “Base R.”↩︎ Because there are so many different ways to achieve the same thing in R, when Googling for help with R, it is useful to append the name of the package or approach you are using, e.g., “how to make a histogram ggplot2.”↩︎ "],
["chapter-2.html", "Chapter 2 Chapter 2 2.1 Loading packages 2.2 Loading data 2.3 Handling numeric factors 2.4 Argument names 2.5 Demographic information 2.6 Bar chart of counts 2.7 Histogram 2.8 Customisation 1 2.9 Activities 1", " Chapter 2 Chapter 2 2.1 Loading packages To load the packages that have the functions we need, use the library() function. Whilst you only need to install packages once, you need to load any packages you want to use with library() every time you start R. When you load the tidyverse, you actually load several separate packages that are all part of the same collection and have been designed to work well together. R will produce a message that tells you the names of all the packages that have been loaded. library(tidyverse) library(patchwork) 2.2 Loading data Download the data here: ldt_data.csv To load the simulated data we use the function read_csv() from the readr tidyverse package. Note that there are many other ways of reading data into R, but the benefit of this function is that it enters the data into the R environment in such a way that it makes most sense for other tidyverse packages. dat &lt;- read_csv(file = &quot;ldt_data.csv&quot;) This code has created an object dat into which you have read the data from the file ldt_data.csv. This object will appear in the environment pane in the top right. Note that the name of the data file must be in quotation marks and the file extension (.csv) must also be included. If you receive the error …does not exist in current working directory it is highly likely that you have made a typo in the file name (remember R is case sensitive), have forgotten to include the file extension, or that the data file you want to load is not stored in your project folder. If you get the error could not find function it means you have either not loaded the correct package, or you have made a typo in the function name. To view the dataset, click dat in the environment pane or run View(dat) in the console. The environment pane also tells us that the object dat has 100 observations of 7 variables, and is a useful quick check to ensure one has loaded the right data. Note that the 7 variables have an additional piece of information chr and num; this specifies the kind of data in the column. Similar to Excel and SPSS, R used this information (or variable type) to specify allowable manipulations of data. For instance character data such as the id can’t be averaged, while it is possible to do this with numerical data such as the age. 2.3 Handling numeric factors Another useful check is to use the functions summary() and str() (structure) to check what kind of data R thinks is in each column. Run the below code and look at the output of each, comparing it with what you know about the simulated dataset: summary(dat) str(dat) Because the factor language is coded as 1 and 2, R has categorised this column as containing numeric information and unless we correct it, this will cause problems for visualisation and analysis. The code below shows how to recode numeric codes into labels. mutate() makes new columns in a data table, or overwrites a column; factor() translates the language column into a factor with the labels “monolingual” and “bilingual.” You can also use factor() to set the display order of a column that contains words. Otherwise, they will display in alphabetical order. n this case we are replacing the numeric data (1 and 2) in the language column with the equivalent English labels monolingual for 1 and bilingual for 2. At the same time we will change the column type to be a factor, which is how R defines categorical data. dat &lt;- dat %&gt;% mutate(language = factor( x = language, # column to translate levels = c(1, 2), # values of the original data in preferred order labels = c(&quot;monolingual&quot;, &quot;bilingual&quot;) # labels for display )) 2.4 Argument names Each function has a list of arguments it can take, and a default order for those arguments. You can get more information on each function by entering ?function_name into the console, although be aware that learning to read the help documentation in R is a skill in itself. When you are writing R code, as long as you stick to the default order, you do not have to explicitly call the argument names, for example, the above code could also be written as: dat &lt;- dat %&gt;% mutate(language = factor(language, c(1, 2), c(&quot;monolingual&quot;, &quot;bilingual&quot;))) One of the challenges in learning R is that many of the “helpful” examples and solutions you will find online do not include argument names and so for novice learners are completely opaque. In this tutorial, we will include the argument names the first time a function is used, however, we will remove some argument names from subsequent examples to facilitate knowledge transfer to the help available online. 2.5 Demographic information You can calculate and plot some basic descriptive information about the demographics of our sample using the imported dataset without any additional wrangling (or data processing). The code below uses the %&gt;% operator, otherwise known as the pipe, and can mostly useful be translated as \"and then\". For example, the below code can be read as: Start with the dataset dat and then; Group it by the variable language and then; Count the number of observations in each group dat %&gt;% group_by(language) %&gt;% count() language n monolingual 55 bilingual 45 group_by() does not result in surface level changes to the dataset, rather, it changes the underlying structure so that if groups are specified, whatever function is called next is performed separately on each level of the grouping variable. The above code therefore counts the number of observations in each group of the variable language. If you just need the total number of observations, you could remove the group_by() line which would perform the operation on the whole dataset, rather than by groups: dat %&gt;% count() n 100 Similarly, we may wish to calculate the mean age (and SD) of the sample and we can do so using the function summarise() from the dplyr tidyverse package. dat %&gt;% summarise(mean_age = mean(age), sd_age = sd(age), n_values = n()) mean_age sd_age n_values 29.75 8.28 100 This code produces summary data in the form of a column named mean_age that contains the result of calculating the mean of the variable age. It then creates sd_age which does the same but for standard deviation. Finally, it uses the function n() to add the number of values used to calculate the statistic in a column named n_values - this is a useful sanity check whenever you make summary statistics. Note that the above code will not save the result of this operation, it will simply output the result in the console. If you wish to save it for future use, you can store it in an object by using the &lt;- notation and print it later by typing the object name. age_stats &lt;- dat %&gt;% summarise(mean_age = mean(age), sd_age = sd(age), n_values = n()) Finally, the group_by() function will work in the same way when calculating summary statistics - the output of the function that is called after group_by() will be produced for each level of the grouping variable. dat %&gt;% group_by(language) %&gt;% summarise(mean_age = mean(age), sd_age = sd(age), n_values = n()) language mean_age sd_age n_values monolingual 27.96 6.78 55 bilingual 31.93 9.44 45 2.6 Bar chart of counts For our first plot, we will make a simple bar chart of counts that shows the number of participants in each language group. ggplot(data = dat, mapping = aes(x = language)) + geom_bar() Figure 2.1: Bar chart of counts. The first line of code sets up the base of the plot. data specifies which data source to use for the plot mapping specifies which variables to map to which aesthetics (aes) of the plot. Aesthetic mappings describe how variables in the data are mapped to visual properties (aesthetics) of geoms. x specifies which variable to put on the x-axis The second line of code adds a geom, and is connected to the base code with +. In this case, we ask for geom_bar(). Each geom has an associated default statistic. For geom_bar(), the default statistic is to count the data passed to it. This means that you do not have to specify a y variable when making a bar plot of counts, when given an x variable, geom_bar() will automatically calculate counts of the groups in that variable. In this example, it counts the number of data points that are in each category of the language variable. The base layer and the geoms you add as layers work in symbiosis so it is worthwhile checking the mapping rules as these are related to the default statistic for the plot’s geom. If your data already have the counts that you want to plot, you can set stat=\"identity\" inside of geom_bar() to use that number instead of counting rows. For example, there is no way to plot percentages rather than counts within ggplot, you need to calculate these and store them in an object which is then used as the dataset. Notice that we are now omitting the names of the arguments data and mapping in the ggplot() function. count_dat &lt;- dat %&gt;% group_by(language) %&gt;% count() %&gt;% ungroup() %&gt;% mutate(percent = (n/sum(n)*100)) ggplot(count_dat, aes(x = language, y = percent)) + geom_bar(stat=&quot;identity&quot;) Figure 2.2: Bar chart of pre-calculated counts. 2.7 Histogram The code to plot a histogram of age is very similar to the bar chart. We start by setting up the plot space, the dataset we want to use, and mapping the variables to the relevant axis. In this case, we want to plot a histogram with age on the x-axis: ggplot(dat, aes(x = age)) + geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. Figure 2.3: Histogram of ages. The base statistic for geom_historgram() is also counts, and by default geom_histogram() divides the x-axis into “bins” and counts how many observations are in each bin and so the y-axis does not need to be specified - it is automatically a count. When you run the code to produce the histogram, you will get the message stat_bin() using bins = 30. Pick better value with binwidth. This means that the default number of bins geom_histogram() divided the x-axis into was 30. For our data that is appropriate as each bin represents one year, but if you we want one bar to equal 5 years, we can adjust binwidth = 5. ggplot(dat, aes(x = age)) + geom_histogram(binwidth = 5) Figure 2.4: Histogram of ages where each bin covers one year. 2.8 Customisation 1 So far we have made basic plots with the default visual appearance, before we move on to the experimental data we will introduce some simple visual customisation options. There are many ways in which you can control or customise the visual appearance of figures in R, however, once you understand the logic of one, it becomes easier to understand others that you may see in online examples. Visual appearance of elements can be customised with within a geom itself, within the aesthetic mapping or by connecting additional layers with+. In this section we look at the simplest and most commonly-used customisations: changing colours, adding axis labels and adding themes. 2.8.1 Changing colours For our basic bar chart, you can control colours used to display the bars by setting fill (internal colour) and colour (outline colour) inside the geom function. This methods changes all the bars; we will show you later how to set fill or colour separately for different groups. ggplot(dat, aes(age)) + geom_histogram(binwidth = 1, fill = &quot;white&quot;, colour = &quot;black&quot;) Figure 2.5: Histogram with custom colors for bar fill and line colors. 2.8.2 Editing axis names and labels To edit axis names and labels you can connect scale_ functions to your plot with + to add layers. These functions are part of ggplot and the one you use depends on which aesthetic you wish to edit (e.g., x-axis, y-axis, fill, colour) as well as the type of data it represents (discrete, continuous). For the bar chart of counts, the x-axis is mapped to a discrete (categorical) variable whilst the y-axis is continuous. For each of these there is a relevant scale function with various elements that can be customised. Each axis then has its own function added as a layer to the basic plot. ggplot(dat, aes(language)) + geom_bar() + scale_x_discrete(name = &quot;Language group&quot;, labels = c(&quot;Monolingual&quot;, &quot;Bilingual&quot;)) + scale_y_continuous(name = &quot;Number of participants&quot;, breaks = c(0,10,20,30,40,50)) Figure 2.6: Bar chart with custom axis labels. name controls the overall name of the axis (note the use of quotation marks) labels controls the names of the conditions with a discrete variable. c() is a function that you will see in many different contexts and is used to combine multiple values. In this case, the labels we want to apply are combined within c() by enclosing each word within their own parenthesis, and are in the order displayed on the plot. breaks controls the tick marks on the axis. Again because there are multiple values, they are enclosed within c() although because they are numeric and not text, they do not need quotation marks. 2.8.3 Adding a theme ggplot has a number of built-in visual themes that you can apply as an extra layer. The below code updates the x-axis and y-axis labels to the histogram, but also applies theme_minimal(). Each part of a theme can be independently customised, which may be necessary, for example, if you have journal guidelines on fonts for publication. There are further instructions for how to do this in the additional resources. ggplot(dat, aes(age)) + geom_histogram(binwidth = 1, fill = &quot;wheat&quot;, color = &quot;black&quot;) + scale_x_continuous(name = &quot;Participant age (years)&quot;) + theme_minimal() Figure 2.7: Histogram with a custom theme. You can set the theme globally so that all subsequent plots use a theme. theme_set(theme_minimal()) If you wished to return to the default theme, change the above to specify theme_grey(). 2.9 Activities 1 Before you move on try the following: Add a layer that edits the name of the y-axis histogram label to Number of participants. Solution ggplot(dat, aes(age)) + geom_histogram(binwidth = 1, fill = &quot;wheat&quot;, color = &quot;black&quot;) + scale_x_continuous(name = &quot;Participant age (years)&quot;) + theme_minimal() + scale_y_continuous(name = &quot;Number of participants&quot;) Change the colour of the bars in the bar chart to red. Solution ggplot(data = dat, mapping = aes(x = language)) + geom_bar(fill = &quot;red&quot;) Remove theme_minimal() from the histogram and instead apply one of the other available themes. To find out about other available themes, start typing theme_ and the auto-complete will show you the available options - this will only work if you have loaded the tidyverse library with library(tidyverse). Solution #multiple options here e.g., theme_classic() ggplot(dat, aes(age)) + geom_histogram(binwidth = 1, fill = &quot;wheat&quot;, color = &quot;black&quot;) + scale_x_continuous(name = &quot;Participant age (years)&quot;) + theme_classic() # theme_bw() ggplot(dat, aes(age)) + geom_histogram(binwidth = 1, fill = &quot;wheat&quot;, color = &quot;black&quot;) + scale_x_continuous(name = &quot;Participant age (years)&quot;) + theme_bw() "],
["chapter-3.html", "Chapter 3 Chapter 3 3.1 Data formats 3.2 Transforming data 3.3 Histogram 2 3.4 Density plots 3.5 Scatterplots 3.6 Customisation 2 3.7 Activities 2", " Chapter 3 Chapter 3 3.1 Data formats To visualise the experimental reaction time and accuracy data using ggplot we first need to perform some data wrangling, and it is this step that can cause friction with novice users of R. Traditionally, wide-format data is the preferred or default format. Wide-format data typically has one row of data for each participant with separate columns for each score or variable. Where there are repeated-measures variables, the dependent variable is split across different columns with one measurement for each condition. The simulated Stroop data is currently in wide-format (see Table 3.1) where each participant’s aggregated3 reaction time and accuracy for each level of the within-subject variable is split across multiple columns. Table 3.1: Data in wide format. id age language rt_cong rt_incon acc_cong acc_incon S001 25 monolingual 369.46 666.82 99 90 S002 37 monolingual 302.45 585.04 94 82 S003 26 monolingual 394.94 608.50 96 87 S004 32 monolingual 288.37 485.89 92 76 S005 28 monolingual 306.42 551.32 91 83 S006 34 monolingual 347.17 517.34 96 78 This format is popular because it is intuitive to read and easy to enter data into as all the data for one participant is contained within a single row. However, for the purposes of analysis, and particularly for analysis using R, this format is unsuitable because whilst it is intuitive to read by a human, the same is not true for a computer . Wide-format data combines multiple variables in a single column, for example in Table 3.1, rt_cong contains information related to both a DV and the level of an IV. Wickham (2014) provides a comprehensive overview of the benefits of tidy data as a standard way of mapping a dataset to its structure, but for the purposes of this tutorial there are two important rules: each column should be a variable and each row should be an observation. Moving from using wide-form to long-form datasets can require a conceptual shift on the part of the researcher and one that usually only comes with practice and repeated exposure4. For our example dataset, adhering to these rules would produce Table 3.2. Rather than different observations of the same dependent variable being split across columns, there is now a single column for the DV reaction time, and a single column for the DV accuracy. Each participant now has multiple rows of data, one for each observation (i.e., for each participant there will be as many rows as there are levels of the within-subject IV). Although there is some repetition of age and language group, each row is unique when looking at the combination of measures. Table 3.2: Data in the correct format for visualization. id age language condition rt acc S001 25 monolingual cong 369.46 99 S001 25 monolingual incon 666.82 90 S002 37 monolingual cong 302.45 94 S002 37 monolingual incon 585.04 82 S003 26 monolingual cong 394.94 96 S003 26 monolingual incon 608.50 87 The benefits and flexibility of this format will hopefully become apparent as we progress through the tutorial, however, a useful rule of thumb when working with data in R for visualisation is that anything that shares an axis should probably be in the same column. For example, a simple bar chart of means for the reaction time DV would display the variable condition on the x-axis with bars representing both the cong and incon data, therefore, these data should be in one column and not split. 3.2 Transforming data We have chosen a 2 x 2 design with two DVs as we anticipate that this is a design many researchers will be familiar with and may also have existing datasets with a similar structure. However, it is worth normalising that trial-and-error is part of the process of learning how to apply these functions to new datasets and structures. Data visualisation can be a useful way to scaffold learning these data transformations because they can provide a concrete visual check as to whether you have done what you intended to do with your data. 3.2.1 Step 1: pivot_longer() The first step is to use the function pivot_longer() to transform the data to long-form. The pivot functions can be easier to show than tell - you may find it a useful exercise to run the below code and compare the newly created object long (Table 3.3) with the original dat Table 3.1 before reading on. long &lt;- pivot_longer(data = dat, cols = rt_cong:acc_incon, names_sep = &quot;_&quot;, names_to = c(&quot;dv_type&quot;, &quot;condition&quot;), values_to = &quot;dv&quot;) As with the other tidyverse functions, the first argument specifies the dataset to use as the base, in this case dat. This argument name is often dropped in examples. cols specifies all the columns you want to transform. The easiest way to visualise this is to think about which columns would be the same in the new long-form dataset and which will change. If you refer back to Table 3.3 and Table 3.1, you can see that id, age, and language all remain, it is the columns that contain the measurements of the DVs that change. The colon notation first_column:last_column is used to select all variables from the first column specified to the second. In our code, cols specifies that the columns we want to transform are rt_cong to acc_incon. names_sep specifies how to split up the variable name in cases where it has multiple components. This is when taking care to name your variables consistently and meaningfully pays off. Because the word to the left of the separator (_) is always the DV type and the word to the right is always the condition of the within-subject IV, it is easy to automatically split the columns. names_to specifies the names of the new columns that will be created. There are two: one for the text to the left of the separator, and one for the text to the right of the separator. Finally, values_to names the new column that will contain the measurements, in this case we’ll call it dv. At this point you may find it helpful to go back and compare dat and long again to see how each argument matches up with the output of the table. Table 3.3: Data in long format. id age language dv_type condition dv S001 25 monolingual rt cong 369.46 S001 25 monolingual rt incon 666.82 S001 25 monolingual acc cong 99.00 S001 25 monolingual acc incon 90.00 S002 37 monolingual rt cong 302.45 S002 37 monolingual rt incon 585.04 3.2.2 Step 2: pivot_wider() Because we have two DVs, we need to perform an additional step. In the current long-form dataset, the column dv contains both reaction time and accuracy measures and keeping in mind the rule of thumb that anything that shares an axis should probably be in the same column, this creates a problem because we cannot plot two different units of measurement on the same axis. To fix this we need to use the function pivot_wider(). Again, we would encourage you at this point to compare long and dat_long with the below code to try and map the connections before reading on. dat_long &lt;- pivot_wider(long, names_from = &quot;dv_type&quot;, values_from = &quot;dv&quot;) The first argument is again the dataset you wish to work from, in this case long. We have removed the argument name data in this example. names_from acts somewhat like the reverse of names_to from pivot_longer(). It will take the values from the variable specified and use these as variable names, i.e., in this case, the values of rt and acc that are currently in the dv_type column, and turn these into the column names. Finally, values_from specifies the values to fill the new columns with. In this case, the new columns rt and acc will be filled with the values that were in dv. Again, it can be helpful to compare each dataset with the code to see how it aligns. This final long-form data should looks like Table 3.3. We have purposefully used a more complex dataset with two DVs for this tutorial. If you are working with a dataset with only one DV, note that only step 1 of this process would be necessary, potentially with the removal of the names_sep argument. Finally, be careful not to calculate demographic descriptive statistics from this long-form dataset. Because the process of transformation has introduced some repetition for these variables, the wide-form dataset where 1 row = 1 participant should be used for demographic information. 3.3 Histogram 2 Now that we have the experimental data in the right form, we can begin to create some useful visualizations. First, to demonstrate how code recipes can be reused and adapted, we will create histograms of reaction time and accuracy. The below code uses the same template as before but changes the dataset (dat_long), the binwidths of the histograms, the x variable to display (rt/acc), and the name of the x-axis. ggplot(dat_long, aes(x = rt)) + geom_histogram(binwidth = 10, fill = &quot;white&quot;, color = &quot;black&quot;) + scale_x_continuous(name = &quot;Reaction time (ms)&quot;) Figure 3.1: Histogram of reaction times. ggplot(dat_long, aes(x = acc)) + geom_histogram(binwidth = 1, fill = &quot;white&quot;, color = &quot;black&quot;) + scale_x_continuous(name = &quot;Accuracy (0-100)&quot;) Figure 3.2: Histogram of accuracy scores. 3.4 Density plots The layer system makes it easy to create new types of plots by adapting existing recipes. For example, rather than creating a histogram, we can create a smoothed density plot by calling geom_density() rather than geom_histogram(). The rest of the code remains identical. ggplot(dat_long, aes(x = rt)) + geom_density()+ scale_x_continuous(name = &quot;Reaction time (ms)&quot;) Figure 3.3: Density plot of reaction time. 3.4.1 Grouped density plots Density plots are most useful for comparing the distributions of different groups of data. Because the dataset is now in long format, it makes it easier to map another variable to the plot because each variable is contained within a single column. In addition to mapping rt to the x-axis, we specify the fill aesthetic to fill the visualisation of each level of the condition variable with different colours. As with the x and y-axis scale functions, we can edit the names and labels of our fill aesthetic by adding on another scale_*_*() layer. Note that the fill here is set inside the aes() function, which tells ggplot to set the fill differently for each value in the condition column. You cannot specify which colour here (e.g., fill=\"red\"), like you could when you set fill inside the geom_*() function before. ggplot(dat_long, aes(x = rt, fill = condition)) + geom_density()+ scale_x_continuous(name = &quot;Reaction time (ms)&quot;) + scale_fill_discrete(name = &quot;Condition&quot;, labels = c(&quot;Congruent&quot;, &quot;Incongruent&quot;)) Figure 3.4: Density plot of reaction times grouped by condition. 3.5 Scatterplots Scatterplots are created by calling geom_point() and require both an x and y variable to be specified in the mapping. ggplot(dat_long, aes(x = rt, y = age)) + geom_point() Figure 3.5: Point plot of reaction time versus age. A line of best fit can be added with an additional layer that calls the function geom_smooth(). The default is to draw a LOESS or curved regression line, however, a linear line of best fit can be specified using method = \"lm\". By default, geom_smooth() will also draw a confidence envelope around the regression line, this can be removed by adding se = FALSE to geom_point(). ggplot(dat_long, aes(x = rt, y = age)) + geom_point() + geom_smooth(method = &quot;lm&quot;) ## `geom_smooth()` using formula &#39;y ~ x&#39; Figure 3.6: Line of best fit for reaction time versus age. 3.5.1 Grouped scatterplots Similar to the density plot, the scatterplot can also be easily adjusted to display grouped data. For geom_point(), the grouping variable is mapped to color rather than fill and the relevant scale_*_*() function is added. ggplot(dat_long, aes(x = rt, y = age, color = condition)) + geom_point() + geom_smooth(method = &quot;lm&quot;) + scale_color_discrete(name = &quot;Condition&quot;, labels = c(&quot;Congruent&quot;, &quot;Incongruent&quot;)) ## `geom_smooth()` using formula &#39;y ~ x&#39; Figure 3.7: Grouped scatter plot of reaction time versus age by condition. 3.6 Customisation 2 3.6.1 Accessible color schemes One of the drawbacks of using ggplot for visualisation is that the default colour scheme is not accessible (or visually appealing). The red and green default palette is difficult for colour-blind people to differentiate, and also does not display well in grey scale. You can specify exact custom colors for your plots, but one easy option is to use the viridis scale functions. These take the same arguments as their default sister functions for updating axis names and labels, but display plots in contrasting colors that can be read by color-blind people and that also print well in grey scale. The viridis scale functions provide a number of different options for the color – try setting option to any letter from A - E to see the different sets. ggplot(dat_long, aes(x = rt, y = age, color = condition)) + geom_point() + geom_smooth(method = &quot;lm&quot;) + # use &quot;viridis_d&quot; instead of &quot;discrete&quot; for better colors scale_color_viridis_d(name = &quot;Condition&quot;, labels = c(&quot;Congruent&quot;, &quot;Incongruent&quot;), option = &quot;E&quot;) ## `geom_smooth()` using formula &#39;y ~ x&#39; Figure 3.8: Use the viridis color scheme for accessibility. 3.7 Activities 2 Before you move on try the following: Use fill to created grouped histograms that display the distributions for rt for each language group separately and also edit the fill axis labels. Try adding position = \"dodge\" to geom_histogram() to see what happens. Solution # fill and axis changes ggplot(dat_long, aes(x = rt, fill = language)) + geom_histogram(binwidth = 10) + scale_x_continuous(name = &quot;Reaction time (ms)&quot;) + scale_fill_discrete(name = &quot;Group&quot;, labels = c(&quot;Monolingual&quot;, &quot;Bilingual&quot;)) # add in dodge ggplot(dat_long, aes(x = rt, fill = language)) + geom_histogram(binwidth = 10, position = &quot;dodge&quot;) + scale_x_continuous(name = &quot;Reaction time (ms)&quot;) + scale_fill_discrete(name = &quot;Group&quot;, labels = c(&quot;Monolingual&quot;, &quot;Bilingual&quot;)) Use scale_*_*() functions to edit the name of the x and y-axis on the scatterplot Solution ggplot(dat_long, aes(x = rt, y = age)) + geom_point() + geom_smooth(method = &quot;lm&quot;) + scale_x_continuous(name = &quot;Reaction time&quot;) + scale_y_continuous(name = &quot;Age&quot;) Use se = FALSE to remove the confidence envelope from the scatterplots Solution ggplot(dat_long, aes(x = rt, y = age)) + geom_point() + geom_smooth(method = &quot;lm&quot;, se = FALSE) + scale_x_continuous(name = &quot;Reaction time&quot;) + scale_y_continuous(name = &quot;Age&quot;) Remove method = \"lm\" from geom_smooth() to produce a curved regression line. Solution ggplot(dat_long, aes(x = rt, y = age)) + geom_point() + geom_smooth() + scale_x_continuous(name = &quot;Reaction time&quot;) + scale_y_continuous(name = &quot;Age&quot;) Replace the default scale_fill_*() on the grouped density plot with the color-blind friendly version. Solution ggplot(dat_long, aes(x = rt, fill = condition)) + geom_density()+ scale_x_continuous(name = &quot;Reaction time (ms)&quot;) + scale_fill_viridis_d(option = &quot;E&quot;, name = &quot;Condition&quot;, labels = c(&quot;Congruent&quot;, &quot;Incongruent&quot;)) In this tutorial we have chosen to gloss over the data wrangling that must occur to get from the raw data to these aggregated values. This type of wrangling requires a more extensive tutorial than this paper can provide but, more importantly, it is still possible to use R for data visualisation having done these preparatory steps using existing workflows that newcomers to R are comfortable with. The aim of this paper is to bypass these initial, often problematic steps and focus on tangible outputs that may then encourage further mastery of reproducible methods.↩︎ That is to say, if you are new to R, know that many before you have struggled with this conceptual shift - it does get better, it just takes time and your preferred choice of cursing.↩︎ "],
["chapter-4.html", "Chapter 4 Chapter 4 4.1 Transforming data 2 4.2 Boxplots 4.3 Violin plots 4.4 Bar chart of means 4.5 Violin-boxplot 4.6 Customisation part 3 4.7 Activities 3", " Chapter 4 Chapter 4 4.1 Transforming data 2 Following the rule anything that shares an axis should probably be in the same column means that we will frequently need our data in long-form when using ggplot2, however, there are some cases when wide-form is necessary. For example, we may wish to visualise the relationship between reaction time in the congruent and incongurent conditions. The easiest way to achieve this in our case would simply be to use the original wide-form data as the input: ggplot(dat, aes(x = rt_cong, y = rt_incon, fill = language)) + geom_point() + geom_smooth(method = &quot;lm&quot;) ## `geom_smooth()` using formula &#39;y ~ x&#39; Figure 4.1: CAPTION THIS FIGURE!! However, there may also be cases when you do not have an original wide-form version and you can use the pivot_wider() function to transform from long to wide. dat_wide &lt;- dat_long %&gt;% pivot_wider(id_cols = &quot;id&quot;, names_from = &quot;condition&quot;, values_from = c(rt,acc)) id rt_cong rt_incon acc_cong acc_incon S001 369.4585 666.8176 99 90 S002 302.4513 585.0404 94 82 S003 394.9407 608.5022 96 87 S004 288.3734 485.8933 92 76 S005 306.4250 551.3214 91 83 S006 347.1710 517.3355 96 78 4.2 Boxplots As with geom_point(), boxplots also require an x and y-variable to be specified. In this case, x must be a discrete, or categorical variable, whilst y must be continuous. ggplot(dat_long, aes(x = condition, y = acc)) + geom_boxplot() Figure 4.2: Basic boxplot. 4.2.1 Grouped boxplots As with histograms and density plots, fill can be used to create grouped boxplots: ggplot(dat_long, aes(x = condition, y = acc, fill = language)) + geom_boxplot() + scale_fill_viridis_d(option = &quot;D&quot;, name = &quot;Group&quot;, labels = c(&quot;Bilingual&quot;, &quot;Monolingual&quot;)) + theme_classic() + scale_x_discrete(name = &quot;Condition&quot;, labels = c(&quot;Congruent&quot;, &quot;Incongruent&quot;)) + scale_y_continuous(name = &quot;Accuracy&quot;) Figure 4.3: Grouped boxplots 4.3 Violin plots Violin plots display the distribution of a dataset and can be created by calling geom_violin(). They are so-called because the shape they make sometimes looks something like a violin. They are essentially a mirrored density plot on its side. Note that the below code is identical to the code used to draw the boxplots above, except for the call to geom_violin() rather than geom_boxplot(). ggplot(dat_long, aes(x = condition, y = acc, fill = language)) + geom_violin() + scale_fill_viridis_d(option = &quot;D&quot;, name = &quot;Group&quot;, labels = c(&quot;Bilingual&quot;, &quot;Monolingual&quot;)) + theme_classic() + scale_x_discrete(name = &quot;Condition&quot;, labels = c(&quot;Congruent&quot;, &quot;Incongruent&quot;)) + scale_y_continuous(name = &quot;Accuracy&quot;) Figure 4.4: Violin plot. 4.4 Bar chart of means Commonly, rather than visualising distributions of raw data researchers will wish to visualise the mean using a bar chart with error bars. Although this is one of the most common data visualisations, it is somewhat unintuitive for novice learners of R to achieve in ggplot. We present this code here because it is a common visualisation, however, we would urge you to use a better visualisation that provides more transparency about the distribution of the raw data such as the violin-boxplots we will present in the next section. Rather than calling a geom_ function, we call stat_summary(). fun specifies the summary function that gives us the y-value we want to plot, in this case, mean geom specifies what shape or plot we want to use to display the summary. For the first layer we will specify bar. ggplot(dat_long, aes(x = condition, y = rt)) + stat_summary(fun = &quot;mean&quot;, geom = &quot;bar&quot;) Figure 4.5: Bar plot of means. To add the error bars, another layer is added with a second call to stat_summary. This time, the function represents the type of error bars we wish to draw, you can choose from mean_se for standard error, mean_cl_normal for confidence intervals, or mean_sdl for standard deviation. width controls the width of the error bars - try changing the value to see what happens. Whilst fun returns a single value (y), fun.data returns the y-values we want to plot plus their minimum and maximum values, in this case, mean_se ggplot(dat_long, aes(x = condition, y = rt)) + stat_summary(fun = &quot;mean&quot;, geom = &quot;bar&quot;) + stat_summary(fun.data = &quot;mean_se&quot;, geom = &quot;errorbar&quot;, width = .2) Figure 4.6: Bar plot of means with error bars representing SE. 4.5 Violin-boxplot The power of the layered system is further highlighted by the ability to combine different types of plots. For example, rather than using a bar chart with error bars, one can easily create a single plot that includes a violin plot, boxplot, and the mean with error bars. This plot requires just two extra lines of code to produce than the bar plot with error bars, yet the amount of information displayed is vastly superior. fatten = NULL removes the median line from the boxplot, which can make it easier to see the mean and error bars. Including this argument will result in the warning message Removed 1 rows containing missing values (geom_segment) and is not a cause for concern. Removing this argument will reinstate the median line. ggplot(dat_long, aes(x = condition, y= rt)) + geom_violin() + # remove the median line with fatten = NULL geom_boxplot(width = .2, fatten = NULL) + stat_summary(fun = &quot;mean&quot;, geom = &quot;point&quot;) + stat_summary(fun.data = &quot;mean_se&quot;, geom = &quot;errorbar&quot;, width = .1) Figure 4.7: Violin-boxplot with mean dot and standard error bars. It is important to note that the order of the layers matters. For example, if we call geom_boxplot() followed by geom_violin(), we get the following mess: ggplot(dat_long, aes(x = condition, y= rt)) + geom_boxplot() + geom_violin() + stat_summary(fun = &quot;mean&quot;, geom = &quot;point&quot;) + stat_summary(fun.data = &quot;mean_se&quot;, geom = &quot;errorbar&quot;, width = .1) Figure 4.8: Plot with the geoms in the wrong order. 4.5.1 Grouped violin-boxplots As with previous plots, another variable can be mapped to fill for the violin-boxplot, however, simply adding fill to the mapping causes the different components of the plot to become misaligned because they have different default positions: ggplot(dat_long, aes(x = condition, y= rt, fill = language)) + geom_violin() + geom_boxplot(width = .2, fatten = NULL) + stat_summary(fun = &quot;mean&quot;, geom = &quot;point&quot;) + stat_summary(fun.data = &quot;mean_se&quot;, geom = &quot;errorbar&quot;, width = .1) Figure 4.9: Grouped violin-boxplots without repositioning. To rectify this we need to adjust the argument position for each of the misaligned layers. position_dodge() instructs R to move (dodge) the position of the plot component by the specified value - what value you need can sometimes take trial and error. ggplot(dat_long, aes(x = condition, y= rt, fill = language)) + geom_violin() + geom_boxplot(width = .2, fatten = NULL, position = position_dodge(.9)) + stat_summary(fun = &quot;mean&quot;, geom = &quot;point&quot;, position = position_dodge(.9)) + stat_summary(fun.data = &quot;mean_se&quot;, geom = &quot;errorbar&quot;, width = .1, position = position_dodge(.9)) Figure 4.10: Grouped violin-boxplots with repositioning. 4.6 Customisation part 3 Combining multiple type of plots can present an issue with the colours, particularly when the viridis scheme is used - in the below example it is hard to make out the black lines of the boxplot and the mean/errorbars. ggplot(dat_long, aes(x = condition, y= rt, fill = language)) + geom_violin() + geom_boxplot(width = .2, fatten = NULL, position = position_dodge(.9)) + stat_summary(fun = &quot;mean&quot;, geom = &quot;point&quot;, position = position_dodge(.9)) + stat_summary(fun.data = &quot;mean_se&quot;, geom = &quot;errorbar&quot;, width = .1, position = position_dodge(.9)) + scale_fill_viridis_d(option = &quot;E&quot;) + theme_minimal() Figure 4.11: A color scheme that makes lines difficult to see. There are a number of solutions to this problem. First, we can change the colour of individual geoms by adding colour = \"colour\" to each relevant geom: ggplot(dat_long, aes(x = condition, y= rt, fill = condition)) + geom_violin() + geom_boxplot(width = .2, fatten = NULL, colour = &quot;grey&quot;) + stat_summary(fun = &quot;mean&quot;, geom = &quot;point&quot;, colour = &quot;grey&quot;) + stat_summary(fun.data = &quot;mean_se&quot;, geom = &quot;errorbar&quot;, width = .1, colour = &quot;grey&quot;) + scale_fill_viridis_d(option = &quot;E&quot;) + theme_minimal() Figure 4.12: Manually changing the line colors. We can also keep the original colours but adjust the transparency of each layer using alpha. Again, the exact values needed can take trial and error: ggplot(dat_long, aes(x = condition, y= rt, fill = condition)) + geom_violin(alpha = .4) + geom_boxplot(width = .2, fatten = NULL, alpha = .5) + stat_summary(fun = &quot;mean&quot;, geom = &quot;point&quot;) + stat_summary(fun.data = &quot;mean_se&quot;, geom = &quot;errorbar&quot;, width = .1) + scale_fill_viridis_d(option = &quot;E&quot;) + theme_minimal() Figure 4.13: Using transparency on the fill color. 4.7 Activities 3 Before you go on, do the following: Review all the code you have run so far. Try to identify the commonalities between each plot’s code and the bits of the code you might change if you were using a different dataset. Take a moment to recognise the complexity of the code you are now able to read. For the violin-boxplot, for geom = \"point\", try changing fun to median Solution ggplot(dat_long, aes(x = condition, y= rt)) + geom_violin() + # remove the median line with fatten = NULL geom_boxplot(width = .2, fatten = NULL) + stat_summary(fun = &quot;median&quot;, geom = &quot;point&quot;) + stat_summary(fun.data = &quot;mean_se&quot;, geom = &quot;errorbar&quot;, width = .1) For the violin-boxplot, for geom = \"errorbar\", try changing fun.data to mean_cl_normal (for 95% CI) Solution ggplot(dat_long, aes(x = condition, y= rt)) + geom_violin() + # remove the median line with fatten = NULL geom_boxplot(width = .2, fatten = NULL) + stat_summary(fun = &quot;mean&quot;, geom = &quot;point&quot;) + stat_summary(fun.data = &quot;mean_cl_normal&quot;, geom = &quot;errorbar&quot;, width = .1) Go back to the grouped density plots and try changing the transparency with alpha. Solution ggplot(dat_long, aes(x = rt, fill = condition)) + geom_density(alpha = .4)+ scale_x_continuous(name = &quot;Reaction time (ms)&quot;) + scale_fill_discrete(name = &quot;Condition&quot;, labels = c(&quot;Congruent&quot;, &quot;Incongruent&quot;)) "],
["chapter-5.html", "Chapter 5 Chapter 5 5.1 Interaction plots 5.2 Combined interaction plots 5.3 Facets 5.4 Saving plots 5.5 Exporting plots 5.6 Multiple plots 5.7 Customisation part 4", " Chapter 5 Chapter 5 5.1 Interaction plots Interaction plots are commonly used to help display or interpret a factorial design. Just like with the bar chart of means, interaction plots represent data summaries and so they are built up with a series of calls to stat_summary(). shape acts much like fill in previous plots, except that rather than producing different colour fills for each level of the IV, the data points are given different shapes. size lets you change the size of lines and points. You usually don’t want different groups to be different sizes, so this option is set inside the relevant geom_*() function, not inside the aes() function. scale_color_manual() works much like scale_color_discrete() except that it lets you specify the colour values manually. You can specify RGB colour values or a list of predefined colour names - all available options can be found by running colours() in the console. Other manual scales are also available, for example, scale_fill_manual. ggplot(dat_long, aes(x = condition, y = rt, shape = language, group = language, color = language)) + stat_summary(fun = &quot;mean&quot;, geom = &quot;point&quot;, size = 3) + stat_summary(fun = &quot;mean&quot;, geom = &quot;line&quot;) + stat_summary(fun.data = &quot;mean_se&quot;, geom = &quot;errorbar&quot;, width = .2) + scale_color_manual(values = c(&quot;blue&quot;, &quot;darkorange&quot;)) + theme_classic() Figure 5.1: Interaction plot. 5.2 Combined interaction plots A more complex interaction plot can be produced that takes advantage of the layers to visualise not only the overall interaction, but the change across conditions for each participant. This code is more complex than all prior code because it does not use a universal mapping of the plot aesthetics. In our code so far, the aesthetic mapping (aes) of the plot has been specified in the first line of code as all layers have used the same mapping, however, is is also possible for each layer to use a different mapping. The first call to ggplot() sets up the default mappings of the plot that will be used unless otherwised specified - the x, y and group variable. geom_point() overrides the default mapping by setting its own colour to draw the data points from each language group in a different colour. alpha is set to a low value to aid readability. Similarly, geom_line() overrides the default grouping varibale so that a line is drawn to connect the individual data points for each participant (group = id) rather than each language group, and also sets the colours. Finally, the calls to stat_summary() remain largely as they were, with the exception of setting colour = \"black\" and size = 2 so that the overall means and errorbars can be more easily distinguished from the individual data points. Because they do not specify an individual mapping, they use the defaults (e.g., the lines are connected by language group). ggplot(dat_long, aes(x = condition, y = rt, group = language, shape = language)) + geom_point(aes(colour = language),alpha = .2) + geom_line(aes(group = id, colour = language), alpha = .2) + stat_summary(fun = &quot;mean&quot;, geom = &quot;point&quot;, size = 2, colour = &quot;black&quot;) + stat_summary(fun = &quot;mean&quot;, geom = &quot;line&quot;, colour = &quot;black&quot;) + stat_summary(fun.data = &quot;mean_se&quot;, geom = &quot;errorbar&quot;, width = .2, colour = &quot;black&quot;) + theme_minimal() Figure 4.1: Interaction plot with by-participant data 5.3 Facets So far we have produced single plots that display all the desired variables in one, however, there are situations in which it may be useful to create separate plots for each level of a variable. The below code is an adaptation of the code used to produce the grouped scatterplot (see Figure X) in which it may be easier to see how the relationship changes when the data are not overlaid. Rather than using colour = condition to produce different colours for each level of condition, this variable is instead passed to facet_wrap(). ggplot(dat_long, aes(x = rt, y = age)) + geom_point() + geom_smooth(method = &quot;lm&quot;) + facet_wrap(~condition) + scale_color_discrete(name = &quot;Condition&quot;, labels = c(&quot;Congruent&quot;, &quot;Incongruent&quot;)) ## `geom_smooth()` using formula &#39;y ~ x&#39; Figure 5.2: Faceted scatterplot As another example, we can use facet_wrap() as an alternative to the grouped violin-boxplot (see Figure X) in which the variable language is passed to facet_wrap() rather than fill. ggplot(dat_long, aes(x = condition, y= rt)) + geom_violin() + geom_boxplot(width = .2, fatten = NULL) + stat_summary(fun = &quot;mean&quot;, geom = &quot;point&quot;) + stat_summary(fun.data = &quot;mean_se&quot;, geom = &quot;errorbar&quot;, width = .1) + facet_wrap(~language) + theme_minimal() Figure 5.3: Facted violin-boxplot Finally, note that editing the labels for faceted variables uses a different, and quite frankly altogether opaque and confusing, syntax calling on the labeller function. ggplot(dat_long, aes(x = condition, y= rt)) + geom_violin() + geom_boxplot(width = .2, fatten = NULL) + stat_summary(fun = &quot;mean&quot;, geom = &quot;point&quot;) + stat_summary(fun.data = &quot;mean_se&quot;, geom = &quot;errorbar&quot;, width = .1) + facet_wrap(~language, labeller = labeller( language = (c(monolingual = &quot;Monolingual participants&quot;, bilingual = &quot;Bilingual participants&quot;)))) + theme_minimal() Figure 5.4: Faceted violin-boxplot with updated labels 5.4 Saving plots Just like with datasets, plots can be saved to objects. The below code saves the histograms we produced for reaction time and accuracy to objects named p1 and p2. These plots can then be viewed by calling the object name in the console. p1 &lt;- ggplot(dat_long, aes(x = rt)) + geom_histogram(binwidth = 10, color = &quot;black&quot;) p2 &lt;- ggplot(dat_long, aes(x = acc)) + geom_histogram(binwidth = 1, color = &quot;black&quot;) Importantly, layers can then be added to these saved objects. For example, the below code adds a theme to the plot saved in p1 and saves it as a new object p3. This is important because many of the examples of ggplot code you will find in online help forums use the p + format to build up plots but fail to explain what this means, which can be confusing to beginners. p3 &lt;- p1 + theme_minimal() 5.5 Exporting plots In addition to saving plots to objects for further use in R, the function ggsave() can be used to save plots to your hard drive. The only required argument for ggsave is the file name of the image file you will create, complete with file extension (this can be “eps,” “ps,” “tex,” “pdf,” “jpeg,” “tiff,” “png,” “bmp,” “svg” or “wmf”). By default, ggsave() will save the last plot displayed, however, you can also specify a specific plot object. ggsave(filename = &quot;my_plot.png&quot;) # save last displayed plot ggsave(filename = &quot;my_plot.png&quot;, plot = p3) # save plot p3 The width, height and resolution of the image can all be manually adjusted and the help documentation for is useful here (?ggsave). 5.6 Multiple plots As well as creating separate plots for each level of a variable using facet_wrap(), you may also wish to display multiple different plots together and the patchwork package provides an intuitive way to do this. patchwork does not require the use of any functions once it is loaded with library(), you simply need to save the plots you wish to combine to objects as above as use the operators +, / () and |. 5.6.1 Combining two plots Two plots can be combined side-by-side or stacked on top of each other. These combined plots could also be saved to an object and then passed to ggsave. p1 + p2 # side-by-side Figure 5.5: Side-by-side plots with patchwork p1 / p2 # stacked Figure 5.6: Stacked plots with patchwork 5.6.2 Combining three or more plots Three or more plots can be combined in a number of ways and the patchwork syntax is relatively easy to grasp with a few examples and a bit of trial and error. First, we save the complex interaction plot and faceted violin-boxplot to objects named p5 and p6. p5 &lt;- ggplot(dat_long, aes(x = condition, y = rt, group = language, shape = language)) + geom_point(aes(colour = language),alpha = .2) + geom_line(aes(group = id, colour = language), alpha = .2) + stat_summary(fun = &quot;mean&quot;, geom = &quot;point&quot;, size = 2, colour = &quot;black&quot;) + stat_summary(fun = &quot;mean&quot;, geom = &quot;line&quot;, colour = &quot;black&quot;) + stat_summary(fun.data = &quot;mean_se&quot;, geom = &quot;errorbar&quot;, width = .2, colour = &quot;black&quot;) + theme_minimal() p6 &lt;- ggplot(dat_long, aes(x = condition, y= rt)) + geom_violin() + geom_boxplot(width = .2, fatten = NULL) + stat_summary(fun = &quot;mean&quot;, geom = &quot;point&quot;) + stat_summary(fun.data = &quot;mean_se&quot;, geom = &quot;errorbar&quot;, width = .1) + facet_wrap(~language, labeller = labeller(language = (c(monolingual = &quot;Monolingual participants&quot;, bilingual = &quot;Bilingual participants&quot;)))) + theme_minimal() The exact layout of your plots will depend upon a number of factors. Try running the below examples and adjust the use of the operators to see how they change the layout. p1 /p5 / p6 (p1 + p6) / p5 p6 | p1 / p5 5.7 Customisation part 4 5.7.1 Axis labels Previously when we edited the main axis labels we used the scale_ functions to do so. These functions are useful to know because they allow you to customise each aspect of the scale, for example, the breaks and limits. However, if you only need to change the main axis name, there is a quicker way to do so using labs(). The below code edits the axis labels for the histogram saved in p1. The title and subtitle do not conform to APA standards (more on APA formatting in the additional resources), however, for presentations and social media they can be useful. p5 + labs(x = &quot;Congruency of stimuli&quot;, y = &quot;Reaction time (ms)&quot;, title = &quot;Language group by congruency interaction plot&quot;, subtitle = &quot;Reaction time data shows evidence of bilingual advantage&quot;) (#fig:Plot with edited labels and title)CAPTION THIS FIGURE!! You can also use labs() to remove axis labels, for example, try adjusting the above code to x = NULL. 5.7.2 Non-meaningful colours So far when we have produced plots with colours, the colours were meaningful in that they represented different levels of a variable, but it is also possible to include colour for purely aesthetic reasons. The below code adds fill = language to the faceted violin-boxplots, in addition to adjusting alpha and using the viridis colour palette. ggplot(dat_long, aes(x = condition, y= rt, fill = language)) + geom_violin(alpha = .4) + geom_boxplot(width = .2, fatten = NULL, alpha = .6) + stat_summary(fun = &quot;mean&quot;, geom = &quot;point&quot;) + stat_summary(fun.data = &quot;mean_se&quot;, geom = &quot;errorbar&quot;, width = .1) + facet_wrap(~language, labeller = labeller(language = (c(monolingual = &quot;Monolingual participants&quot;, bilingual = &quot;Bilingual participants&quot;)))) + theme_minimal() + scale_fill_viridis_d(option = &quot;E&quot;) Figure 5.7: Violin-boxplot with redundant legend Specifying a fill variable means that by default, R has produced a legend for that variable. However, given that the use of colour is not meaningful, this is a waste of plot space (it provides no more information than what is represented already by the x-axis). You can remove this legend with the guides function. ggplot(dat_long, aes(x = condition, y= rt, fill = language)) + geom_violin(alpha = .4) + geom_boxplot(width = .2, fatten = NULL, alpha = .6) + stat_summary(fun = &quot;mean&quot;, geom = &quot;point&quot;) + stat_summary(fun.data = &quot;mean_se&quot;, geom = &quot;errorbar&quot;, width = .1) + facet_wrap(~language, labeller = labeller(language = (c(monolingual = &quot;Monolingual participants&quot;, bilingual = &quot;Bilingual participants&quot;)))) + theme_minimal() + scale_fill_viridis_d(option = &quot;E&quot;) + guides(fill = FALSE) Figure 5.8: Plot with suppressed redundant legend "],
["chapter-6.html", "Chapter 6 Chapter 6", " Chapter 6 Chapter 6 ridge Alluvial raincloud split-violin "],
["additional-resources.html", "A Additional resources", " A Additional resources "],
["additional-resources-phil.html", "B Additional Resources - Phil B.1 Adding lines to plots B.2 Zooming in and out B.3 Setting the axis values B.4 Controlling the Legend B.5 Setting A Lab Theme using theme() B.6 Easter Egg - Overlaying Plots B.7 Easter Egg - A Dumbbell Plot B.8 Easter Egg - A Pie Chart B.9 Additional Links", " B Additional Resources - Phil There are a number of incredible resources online that, using the basis we have shown in this paper, will allow you to start adapting your figures and plots to the look you want, making them as informative as possible for your reader. We will list a few of those resoures below, but first we will show you a couple of additional tricks that are often used to help add information to your figure, as well as a couple of additional plot types. B.1 Adding lines to plots Vertical Lines - geom_vline() Often it can be useful to put a marker into our plots to highlight a certain criterion value. For example, if you were working with a scale that has a cut-off, perhaps the Austim Spectrum Quotient 10 (), then you might want to put a line at a score of 7; the point at which the researchers suggest the participant is referred further. Alternatively, thinking about the Stroop test we have looked at in this paper, perhaps you had a level of accuracy that you wanted to make sure was reached - let’s say 80%. If we refer back to Figure 3.2, which used the code below: ggplot(dat_long, aes(x = acc)) + geom_histogram(binwidth = 1, fill = &quot;white&quot;, color = &quot;black&quot;) + scale_x_continuous(name = &quot;Accuracy (0-100)&quot;) and displayed the spread of the accuracy scores as such: Figure B.1: Histogram of accuracy scores. if we wanted to add a line at the 80% level then we could use the geom_vline() function, again from the ggplot2, with the argument of xintercept = 80, meaning cut the x-axis at 80, as follows: ggplot(dat_long, aes(x = acc)) + geom_histogram(binwidth = 1, fill = &quot;white&quot;, color = &quot;black&quot;) + scale_x_continuous(name = &quot;Accuracy (0-100)&quot;) + geom_vline(xintercept = 80) Figure B.2: Histogram of accuracy scores with black solid vertical line indicating 80% accuracy. Now that looks ok but the line is a bit hard to see so we can change the style (linetype = value), color (color = \"color\") and weight (size = value) as follows: ggplot(dat_long, aes(x = acc)) + geom_histogram(binwidth = 1, fill = &quot;white&quot;, color = &quot;black&quot;) + scale_x_continuous(name = &quot;Accuracy (0-100)&quot;) + geom_vline(xintercept = 80, linetype = 2, color = &quot;red&quot;, size = 1.5) Figure B.3: Histogram of accuracy scores with red dashed vertical line indicating 80% accuracy. Horizontal Lines - geom_hline() Another situation may be that you want to put a horizontal line on your figure to mark a value of interest on the y-axis. Again thinking about our Stroop experiment, perhaps we wanted to indicate the 80% accuracy line on our boxplot figures. If we look at Figure 4.2, which used this code to display the basic boxplot: ggplot(dat_long, aes(x = condition, y = acc)) + geom_boxplot() Figure B.4: Basic boxplot. we could then use the geom_hline() function, from the ggplot2, with, this time, the argument of yintercept = 80, meaning cut the y-axis at 80, as follows: ggplot(dat_long, aes(x = condition, y = acc)) + geom_boxplot() + geom_hline(yintercept = 80) Figure B.5: Basic boxplot with black solid horizontal line indicating 80% accuracy. and again we can embellish the line using the same arguements as above. We will put in some different values here just to show the changes: ggplot(dat_long, aes(x = condition, y = acc)) + geom_boxplot() + geom_hline(yintercept = 80, linetype = 3, color = &quot;blue&quot;, size = 2) Figure B.6: Basic boxplot with blue dotted horizontal line indicating 80% accuracy. LineTypes One thing worth noting is that the linetype argument can actually be specified as both a value or as a word. They match up as follows: Value Word linetype = 0 linetype = “blank” linetype = 1 linetype = “solid” linetype = 2 linetype = “dashed” linetype = 3 linetype = “dotted” linetype = 4 linetype = “dotdash” linetype = 5 linetype = “longdash” linetype = 6 linetype = “twodash” Diagonal Lines - geom_abline() The last type of line you might want to overlay on a figure is perhaps a diagonal line. For example, perhaps you have created a scatterplot and you want to have the true diagonal line for reference to the line of best fit. To show this, we will refer back to Figure 3.6 which displayed the line of best fit for the reaction time versus age, and used the following code: ggplot(dat_long, aes(x = rt, y = age)) + geom_point() + geom_smooth(method = &quot;lm&quot;) Figure B.7: Line of best fit for reaction time versus age. By eye that would appear to be a fairly flat relationship but we will add the true diagonal to help clarify. To do this we use the geom_abline(), again from ggplot2, and we give it the arguements of the slope (slope = value) and the intercept (intercept = value). We are also going to scale the data to turn it into z-scores to help us visualise the relationship better, as follows: dat_long_scale &lt;- dat_long %&gt;% mutate(rt_zscore = (rt - mean(rt))/sd(rt), age_zscore = (age - mean(age))/sd(age)) ggplot(dat_long_scale, aes(x = rt_zscore, y = age_zscore)) + geom_point() + geom_smooth(method = &quot;lm&quot;) + geom_abline(slope = 1, intercept = 0) Figure B.8: Line of best fit (blue line) for reaction time versus age with true diagonal shown (black line). So now we can see the line of best fit (blue line) in relation to the true diagonal (black line). We will come back to why we z-scored the data in a minute, but first let’s finish tidying up this figure, using some of the customisation we have seen as it is a bit messy. Something like this might look cleaner: ggplot(dat_long_scale, aes(x = rt_zscore, y = age_zscore)) + geom_abline(slope = 1, intercept = 0, linetype = &quot;dashed&quot;, color = &quot;black&quot;, size = .5) + geom_hline(yintercept = 0, linetype = &quot;solid&quot;, color = &quot;black&quot;, size = .5) + geom_vline(xintercept = 0, linetype = &quot;solid&quot;, color = &quot;black&quot;, size = .5) + geom_point() + geom_smooth(method = &quot;lm&quot;) Figure B.9: Line of best fit (blue solid line) for reaction time versus age with true diagonal shown (black line dashed). That maybe looks a bit cluttered but it gives a nice example of how you can use the different geoms for adding lines to add information to your figure, clearly visualising the weak relationship between reaction time and age. Note: Do remember about the layering system however; you will notice that in the code for B.9 we have changed the order of the code lines so that the geom lines are behind the points! Top Tip: Your intercepts must be values you can see Thinking back to why we z-scored the data for that last figure, we sort of skipped over that, but it did serve a purpose. Here is the original data and the original scatterplot but with the geom_abline() added to the code: ggplot(dat_long, aes(x = rt, y = age)) + geom_point() + geom_smooth(method = &quot;lm&quot;) + geom_abline(slope = 1, intercept = 0) Figure B.10: Line of best fit (blue solid line) for reaction time versus age with missing true diagonal. The code runs but the diagonal line is nowhere to be seen. The reason is that you figure is zoomed in on the data and the diagonal is “out of shot” if you like. If we were to zoom out on the data we would then see the diagonal line as such: ggplot(dat_long, aes(x = rt, y = age)) + geom_point() + geom_smooth(method = &quot;lm&quot;) + geom_abline(slope = 1, intercept = 0) + coord_cartesian(xlim = c(0,1000), ylim = c(0,60)) Figure B.11: Zoomed out to show Line of best fit (blue solid line) for reaction time versus age with true diagonal (black line). So the key point is that your intercepts have to be set to visible for values for you to see them! If you run your code and the line does not appear, check that the value you have set can actually be seen on your figure. This applies to geom_abline(), geom_hline() and geom_vline(). B.2 Zooming in and out Like in the example above, it can be very beneficial to be able to zoom in and out of figures, mainly to focus the frame on a given section. One function we can use to do this is the coord_cartesian(), in ggplot2. The main arguments are the limits on the x-axis (xlim = c(value, value)), the limits on the y-axis (ylim = c(value, value)), and whether to add a small expansion to those limits or not (expand = TRUE/FALSE). Looking at the scatterplot of age and reaction time again, we could use coord_cartesian() to zoom fully out: ggplot(dat_long, aes(x = rt, y = age)) + geom_point() + geom_smooth(method = &quot;lm&quot;) + coord_cartesian(xlim = c(0,1000), ylim = c(0,100), expand = FALSE) Figure B.12: Zoomed out on scatterplot with no expansion around set limits And we can add a small expansion by changing the expand argument to TRUE: ggplot(dat_long, aes(x = rt, y = age)) + geom_point() + geom_smooth(method = &quot;lm&quot;) + coord_cartesian(xlim = c(0,1000), ylim = c(0,100), expand = TRUE) Figure B.13: Zoomed out on scatterplot with small expansion around set limits Or we can zoom right in on a specific area of the plot if there was something we wanted to highlight. Here for example we are just showing the reaction times between 500 and 725 msecs, and all ages between 15 and 55: ggplot(dat_long, aes(x = rt, y = age)) + geom_point() + geom_smooth(method = &quot;lm&quot;) + coord_cartesian(xlim = c(500,725), ylim = c(15,55), expand = TRUE) Figure B.14: Zoomed in on scatterplot with small expansion around set limits And you can zoom in and zoom out just the x-axis or just the y-axis; just depends on what you want to show. B.3 Setting the axis values Continuous scales You may have noticed that depending on the spread of your data, and how much of the figure you see, the values on the axes tend to change. Often we don’t want this and want the values to be constant. We have already used functions to control this in the main body of the paper - the scale_* functions. Here we will use scale_x_continuous() and scale_y_continuous() to set the values on the axes to what we want. The main arguments in both functions are the limits (limts = c(value, value)) and the breaks (the tick marks essentially, breaks = value:value). Note that the limits are just two values (minimum and maximum), whereas the breaks are a series of values (from 0 to 100, for example). If we use the scatterplot of age and reaction time, then our code might look like this: ggplot(dat_long, aes(x = rt, y = age)) + geom_point() + geom_smooth(method = &quot;lm&quot;) + scale_x_continuous(limits = c(0,1000), breaks = 0:1000) + scale_y_continuous(limits = c(0,100), breaks = 0:100) Figure B.15: Changing the values on the axes That actually looks rubbish because we simply have too many values on our axes, so we can use the seq() function, from baseR, to get a bit more control. The arguments here are the first value (from = value), the last value (last = value), and the size of the steps (by = value). For example, seq(0,10,2) would give all values between 0 and 10 in steps of 2, (i.e. 0, 2, 4, 6, 8 and 10). So using that idea we can change the y-axis in steps of 5 (years) and the x-axis in steps of 50 (msecs) as follows: ggplot(dat_long, aes(x = rt, y = age)) + geom_point() + geom_smooth(method = &quot;lm&quot;) + scale_x_continuous(limits = c(0,1000), breaks = seq(0,1000,50)) + scale_y_continuous(limits = c(0,100), breaks = seq(0,100,5)) Figure B.16: Changing the values on the axes using the seq() function Which gives us a much nicer and cleaner set of values on our axes. And if we combine that approach for setting the axes values with our zoom function (coord_cartesian()), then we can get something that looks like this: ggplot(dat_long, aes(x = rt, y = age)) + geom_point() + geom_smooth(method = &quot;lm&quot;) + scale_x_continuous(limits = c(0,1000), breaks = seq(0,1000,50)) + scale_y_continuous(limits = c(0,100), breaks = seq(0,100,5)) + coord_cartesian(xlim = c(250,750), ylim = c(15,55)) Figure B.17: Combining scale functions and zoom functions Which actually looks much like our original scatterplot but with better definition on the axes. So you can see we can actually have a lot of control over the axes and what we see. One thing to note however is that you should not use the limits argument within the scale_* functions as a zoom. It won’t work like that and instead will just disregard data. Look at this example: ggplot(dat_long, aes(x = rt, y = age)) + geom_point() + geom_smooth(method = &quot;lm&quot;) + scale_x_continuous(limits = c(500,600)) ## Warning: Removed 165 rows containing non-finite values (stat_smooth). ## Warning: Removed 165 rows containing missing values (geom_point). Figure B.18: Combining scale functions and zoom functions It may look like it has zoomed in on the data but actually it has removed all data outwith the limits. That is what the warnings are telling you, and you can see that as there is no data above and below the limits, but we know there should be based on the earlier plots. So scale_* functions can change the values on the axes, but coord_cartesian() is for zooming in and out. Discrete scales The same idea of limits within a scale_* function can also be used to change the order of categories on a discrete scale. For example if we look at our boxplots again in Figure 4.13, we see this figure: ggplot(dat_long, aes(x = condition, y= rt, fill = condition)) + geom_violin(alpha = .4) + geom_boxplot(width = .2, fatten = NULL, alpha = .5) + stat_summary(fun = &quot;mean&quot;, geom = &quot;point&quot;) + stat_summary(fun.data = &quot;mean_se&quot;, geom = &quot;errorbar&quot;, width = .1) + scale_fill_viridis_d(option = &quot;E&quot;) + theme_minimal() Figure B.19: Using transparency on the fill color. The figures always default to the alphabetical order. Sometimes that is what we want; sometimes that is not what we want. If we wanted to switch the order of cong and incong so that the incongruent condition comes first we would use the scale_x_discrete() function and set the limits within it (limits = c(\"category\",\"category\")) as follows: ggplot(dat_long, aes(x = condition, y= rt, fill = condition)) + geom_violin(alpha = .4) + geom_boxplot(width = .2, fatten = NULL, alpha = .5) + stat_summary(fun = &quot;mean&quot;, geom = &quot;point&quot;) + stat_summary(fun.data = &quot;mean_se&quot;, geom = &quot;errorbar&quot;, width = .1) + scale_fill_viridis_d(option = &quot;E&quot;) + scale_x_discrete(limits = c(&quot;incon&quot;,&quot;cong&quot;)) + theme_minimal() Figure B.20: Switching orders of categorical variables And that works just the same if you have more conditions, which you will see if you compare Figure 4.11 to the below figure where we have flipped the order of incongruent and congruent from the original default alphabetical order ggplot(dat_long, aes(x = condition, y= rt, fill = language)) + geom_violin() + geom_boxplot(width = .2, fatten = NULL, position = position_dodge(.9)) + stat_summary(fun = &quot;mean&quot;, geom = &quot;point&quot;, position = position_dodge(.9)) + stat_summary(fun.data = &quot;mean_se&quot;, geom = &quot;errorbar&quot;, width = .1, position = position_dodge(.9)) + scale_fill_viridis_d(option = &quot;E&quot;) + scale_x_discrete(limits = c(&quot;incon&quot;,&quot;cong&quot;)) + theme_minimal() Figure B.21: Same as earlier figure but with order of conditions on x-axis altered. Changing Order of Factors Again, you have a lot of control beyond the default alphabetical order that ggplot2 tends to plot in. One question you might have though is why monolingual and bilingual are not in alphabetical order? f they were then the bilingual condition would be plotted first. The answer is, thinking back to the start of the paper, we changed our conditions from 1 and 2 to the factor names of monolingual and bilingual, and ggplot maintains that factor order when plotting. So if we want to plot it in a different fashion we need to do a bit of factor reordering. This can be done much like earlier using the factor() function and stating the order of conditions we want (levels = c(\"factor\",\"factor\")). But be careful with spelling as it must match up to the names of the factors that already exist. In this example, we will reorder the factors so that bilingual is presented first but leave the order of congruent and incongruent as the alphabetical default. Note in the code though that we are not permanently storing the factor change as we don’t want to keep this new order. We are just changing the order “on the fly” for this one example before putting it into the plot. dat_long %&gt;% mutate(language = factor(language, levels = c(&quot;bilingual&quot;,&quot;monolingual&quot;))) %&gt;% ggplot(aes(x = condition, y= rt, fill = language)) + geom_violin() + geom_boxplot(width = .2, fatten = NULL, position = position_dodge(.9)) + stat_summary(fun = &quot;mean&quot;, geom = &quot;point&quot;, position = position_dodge(.9)) + stat_summary(fun.data = &quot;mean_se&quot;, geom = &quot;errorbar&quot;, width = .1, position = position_dodge(.9)) + scale_fill_viridis_d(option = &quot;E&quot;) + theme_minimal() Figure B.22: Same as earlier figure but with order of conditions on x-axis altered. And if we compare this new figure to the original, side-by-side, we see the difference: Figure B.23: Switching factor orders B.4 Controlling the Legend Using the guides() Whilst we are on the subject of changing order and position of elements of the figure, you might think about changing the position of a figure legend. There is actually a few ways of doing it but a simple approach is to use the the guides() function and add that to the ggplot chain. For example, if we run the below code and look at the output: ggplot(dat_long, aes(x = condition, y= rt, fill = condition)) + geom_violin(alpha = .4) + geom_boxplot(width = .2, fatten = NULL, alpha = .5) + stat_summary(fun = &quot;mean&quot;, geom = &quot;point&quot;) + stat_summary(fun.data = &quot;mean_se&quot;, geom = &quot;errorbar&quot;, width = .1) + scale_fill_viridis_d(option = &quot;E&quot;) + guides(fill = &quot;none&quot;) + theme_minimal() Figure B.24: Figure Legend removed using guides() We see the same display as Figure B.19 but with no legend. That is quite useful because the legend just repeats the x-axis and becomes redundant. The guides() function works but setting the legened associated with the fill layer (i.e. fill = condition) to \"none\", basically removing it. One thing to note with this approach is that you need to set a guide for every legend, otherwise a legend will appear. What that means is that if you had set both fill = condition and color = condition, then you would need to set both fill and color to \"none\" within guides() as follows: ggplot(dat_long, aes(x = condition, y= rt, fill = condition, color = condition)) + geom_violin(alpha = .4) + geom_boxplot(width = .2, fatten = NULL, alpha = .5) + stat_summary(fun = &quot;mean&quot;, geom = &quot;point&quot;) + stat_summary(fun.data = &quot;mean_se&quot;, geom = &quot;errorbar&quot;, width = .1) + scale_fill_viridis_d(option = &quot;E&quot;) + guides(fill = &quot;none&quot;, color = &quot;none&quot;) + theme_minimal() Figure B.25: Removing more than one legend with guides() Whereas if you hadn’t used guides() you would see the following: ggplot(dat_long, aes(x = condition, y= rt, fill = condition, color = condition)) + geom_violin(alpha = .4) + geom_boxplot(width = .2, fatten = NULL, alpha = .5) + stat_summary(fun = &quot;mean&quot;, geom = &quot;point&quot;) + stat_summary(fun.data = &quot;mean_se&quot;, geom = &quot;errorbar&quot;, width = .1) + scale_fill_viridis_d(option = &quot;E&quot;) + theme_minimal() Figure B.26: Figure with more than one Legend The key thing to note here is that in the above figure there is actually two legends (one for fill and one for color) but they are overlaid on top of each other as they are associated with the same variable. You can test this by removing either one of the options from the guides() function. One of the legends will still remain. So you need to turn them both off or you can use it to leave certain parts clear. Using the theme() An alternative to the guides function is using the theme() function. The theme() function can actually be used to control a whole host of options in the plot, which we will come on to, but you can use it as a quick way to turn off the legend as follows: ggplot(dat_long, aes(x = condition, y= rt, fill = condition, color = condition)) + geom_violin(alpha = .4) + geom_boxplot(width = .2, fatten = NULL, alpha = .5) + stat_summary(fun = &quot;mean&quot;, geom = &quot;point&quot;) + stat_summary(fun.data = &quot;mean_se&quot;, geom = &quot;errorbar&quot;, width = .1) + scale_fill_viridis_d(option = &quot;E&quot;) + theme_minimal() + theme(legend.position = &quot;none&quot;) Figure B.27: Removing the legend with theme() What you can see is that within the theme() function we set an argument for legend.position and we set that to \"none\" - again removing the legend entirely. One difference to note here is that it removes all aspects of the legend where as, as we said, using guides() allows you to control different parts of the legend (either leaving the fill or color showing or both). So using the legend.position = \"none\" is a bit more brute force and can be handy when you are using various different means of distinguishing between conditions of a variable and don’t want to have to remove each aspect using the guides(). An extension here of course is not just removing the legend, but moving the legend to a different position. This can be done by setting legend.position = ... to either \"top\", \"bottom\", \"left\" or \"right\" as shown: Figure B.28: Legend position options using theme() Or even as a coordinate within your figure expressed as a propotion of your figure - i.e. c(x = 0, y = 0) would be the bottom left of your figure and c(x = 1, y = 1) would be the top right, as shown here: Figure B.29: Legend position options using theme() And so with a little trial and error you can position your legend where you want it without crashing into your figure, hopefully! B.5 Setting A Lab Theme using theme() The theme() function, as we mentioned, does a lot more than just change the position of a legend and can be used to really control a variety of elements and to eventually create your own “theme” for your figures - say you want to have a consistent look to your figures across your publications or across your lab posters. We will try to show some of that here, but first lets start with a very basic plot that we have seen before: THIS BIT NEEDS WORK # set up custom theme to add to all plots mytheme &lt;- theme_minimal( # always start with a base theme_**** base_size = 16, # 16-point font (adjusted for axes) base_family = &quot;Helvetica&quot; # font style ) + # add more specific customisations with theme() theme( text = element_text(color = &quot;white&quot;), # most text axis.text = element_text(color = &quot;grey60&quot;), # axis label text axis.line = element_line(color = &quot;grey60&quot;), # x and y axes plot.background = element_rect(fill = &quot;black&quot;), # main background panel.background = element_blank(), # defaults to plot background fill panel.grid = element_blank() # get rid of gridlines ) # plot with custom theme ggplot(diamonds, aes(carat, price, color = cut)) + geom_smooth() + mytheme Figure 4.1: buidling something like this idea B.6 Easter Egg - Overlaying Plots Hopefully from some of the materials we have shown you, you will have found ways of presenting data in an informative manner - for example, we have shown violin plots and how they can be effective, when combined with boxplots, at displaying distributions. However, if you are familiar with other software you may be used to seeing this sort of information displayed differently, as perhaps a histogram with a normal curve overlaid. Whist the violin plots are better to convey that information we thought it might help to see alternative approaches here. Really it is about overlaying some of the plots we have already shown, but with some slight adjustments. FOr example, lets look at the histogram and density plot of reaction times we saw earlier - shown here side by side for convenience. a &lt;- ggplot(dat_long, aes(x = rt)) + geom_histogram(binwidth = 10, fill = &quot;white&quot;, color = &quot;black&quot;) + scale_x_continuous(name = &quot;Reaction time (ms)&quot;) + labs(subtitle = &quot;+ geom_histogram()&quot;) b &lt;- ggplot(dat_long, aes(x = rt)) + geom_density()+ scale_x_continuous(name = &quot;Reaction time (ms)&quot;) + labs(subtitle = &quot;+ geom_density()&quot;) a+b Figure 5.2: CAPTION THIS Now that in itself is fairly informative but perhaps takes up a lot of room so one option using some of the features of the patchwork library would be to inset the density plot in the top right of the histogram. We already showed a little of patchwork earlier so we won’t repeat it here but all we are doing is placing one of the figures (the density plot) within the inset_element() function and applying some appropriate values to position the inset - through a little trial and error - based on the bottom left corner of the plot area being left = 0, bottom = 0, and the top right corner being right = 1, top = 1: a &lt;- ggplot(dat_long, aes(x = rt)) + geom_histogram(binwidth = 10, fill = &quot;white&quot;, color = &quot;black&quot;) + scale_x_continuous(name = &quot;Reaction time (ms)&quot;) b &lt;- ggplot(dat_long, aes(x = rt)) + geom_density()+ scale_x_continuous(name = &quot;Reaction time (ms)&quot;) a + inset_element(b, left = 0.6, bottom = 0.6, right = 1, top = 1) Figure B.30: Insetting a plot within a plot using inset_element() from the patchwork library But of course that only works if there is space for the inset and it doesn’t start overlapping on the main figure. This next approach fully overlays the density plot on top of the histogram. There is one main change though and that is the addition of aes(y=..density..) within geom_histogram(). This tells the histogram to now be plotted in terms of density and not count, meaning that the density plot and the histogram and now based on the same y-axis: ggplot(dat_long, aes(x = rt)) + geom_histogram(aes(y = ..density..), binwidth = 10, fill = &quot;white&quot;, color = &quot;black&quot;) + geom_density()+ scale_x_continuous(name = &quot;Reaction time (ms)&quot;) Figure B.31: A histogram with density plot overlaid The main thing to not in the above figure is that both the histogram and the density plot are based on the data you have collected. An alternative that you might want to look at it is plotting a normal distribution on top of the histogram based on the mean and standard deviation of the data. This is a bit more complicated but works as follows: ggplot(dat_long, aes(rt)) + geom_histogram(aes(y = ..density..), binwidth = 10, fill = &quot;white&quot;, color = &quot;black&quot;) + stat_function( fun = dnorm, args = list(mean = mean(dat_long$rt), sd = sd(dat_long$rt)) ) Figure B.32: A histogram with normal distribution based on the data overlaid The first part of this approach is identical to what we say above but instead of using geom_density() we are using a statistics function called stat_function() similar to ones we saw earlier when plotting means and standard deviations. What stat_function() is doing is taking the Normal distribution density function, fun = dnorm (read as function equals density normal), and then the mean of the data (mean = mean(dat_long$rt)) and the standard deviation of the data sd = sd(dat_long$rt) and creates a distribution based on those values. The args refers to the arguments that the dnorm function takes, and they are passed to the function as a list (list()). But from there, you can then start to alter the linetype, color, and thickness (lwd = 3 for example) as you please. ggplot(dat_long, aes(rt)) + geom_histogram(aes(y = ..density..), binwidth = 10, fill = &quot;white&quot;, color = &quot;black&quot;) + stat_function( fun = dnorm, args = list(mean = mean(dat_long$rt), sd = sd(dat_long$rt)), color = &quot;red&quot;, lwd = 3, linetype = 2 ) Figure B.33: Changing the line of the stat_function() B.7 Easter Egg - A Dumbbell Plot A nice way of representing a change across different conditions, within participants or across timepoints, is the dumbbell chart. These figures can do a lot of heavy lifting in conveying patterns within the data and are not as hard to create in ggplot as they might first appear. The premis is that you need the start point, in terms of x (x =) and y (y =), and the end point, again in terms of x (xend =) and y (yend =). You draw a line between those two points using geom_segment() and then add a data point at the both ends of the line using geom_point(). So for example, we will use the average accuracy scores for the congruent and incongruent conditions, for monolingual and bilinguals, to demonstrate. We could do the same figure for all participants but as we have 100 participants it can be a bit wild. We first need to create the averages using a little bit of data wrangling we have seen: dat_avg &lt;- dat %&gt;% group_by(language) %&gt;% summarise(mean_acc_incong = mean(acc_incon), mean_acc_cong = mean(acc_cong)) So our data looks as follows: language mean_acc_incong mean_acc_cong monolingual 84.87273 94.87273 bilingual 84.93333 95.17778 With our average accuracies for incongruent trials in mean_acc_incong and our average accuracies for congruent trials in mean_acc_cong. And now we can create our dumbbell plot as follows: ggplot(dat_avg) + geom_segment(aes(x = mean_acc_incong, y = language, xend = mean_acc_cong, yend = language)) + geom_point(aes(x = mean_acc_incong, y = language), color = &quot;red&quot;) + geom_point(aes(x = mean_acc_cong, y = language), color = &quot;blue&quot;) + labs(x = &quot;Change in Accuracy&quot;) Figure B.34: A dumbbell plot of change in Average Accuracy from Incongruent trials (red dots) to Congruent trials (blue dots) for monolingual and bilingual participants. Which actually gives the least exciting figure ever as both groups showed the same change from the incongruent trials (red dots) to the congruent trials (blue dots) but we can break the code down a bit just to highlight what we are doing, remembering the idea about layers. Layers one and two add the basic background and black line from the start point (x,y), the mean accuracy of incongruent trials for the two conditions, to the end point (xend, yend), the mean accuract of congruent trials for the two conditions: Figure B.35: Building the bars of our dumbbells. The (x,y) and (xend, yend) have been added to show the values you need to consider and enter to create the dumbbell and the remaining lines add the dots at the end of the dumbells and changes the x axis label to something useful: Figure B.36: Adding the weights to the dumbbells. Red dots are added in one layer to show Average Accuracy of Incongruent trials, and blue dots are added in final layer to show Average Accuracy of Congruent trials. Of course, worth remembering, it is better to always think of the dumbbell as a start and end point, not left and right, as had accuracy gone down when moving from Incongruent trials to Congruent trials then our bars would run the opposite direction. If you repeat the above process using reaction times instead of accuracy you will see what we mean. B.8 Easter Egg - A Pie Chart Pie Charts are not the best form of visualisation as they generally require people to compare areas and/or angles which is a fairly unintuitive means of doing a comparison. The are so disliked in many fields that ggplot does not actually have a geom_...() function to create one. But, there is always somebody that wants to create a pie chart regardless and who are we to judge. So here would be the code to produce a pie chart of the demographic data we saw in the start of the paper: count_dat &lt;- dat %&gt;% group_by(language) %&gt;% count() %&gt;% ungroup() %&gt;% mutate(percent = (n/sum(n)*100)) ggplot(count_dat, aes(x = &quot;&quot;, y = percent, fill = language)) + geom_bar(width = 1, stat=&quot;identity&quot;) + coord_polar(&quot;y&quot;, start = 0) + theme( axis.title = element_blank(), panel.grid = element_blank(), panel.border = element_blank(), axis.ticks = element_blank(), axis.text.x = element_blank() ) + geom_text(aes(y = c(75, 25), label = paste(percent, &quot;%&quot;)), size = 6) Figure B.37: A pie chart of the demographics The thing to note is really that this is effectively creating a stacked bar chart with no x variable (i.e. x = \"\") and then wrapping the y-axis into a circle (i.e. coord_polar(\"y\", start = 0)). That is what the first three lines of the ggplot code does: Figure B.38: The basis of a pie chart The remainder of the code is used to remove the various panel and tick lines, and text, setting them all to element_blank() through the theme() functions we saw above, and to add new labelling text on top of the piechart at specific y-values (i.e. y = c(75,25)). But remember, friends don’t let friends make piecharts! B.9 Additional Links Bertini, Enrico, and Moritz Stefaner. 2015. “Amanda Cox on Working with r, NYT Projects, Favorite Data [Podcast].” Data Stories. https://datastori.es/ds-56-amanda-cox-nyt/. Munafò, Marcus R, Brian A Nosek, Dorothy VM Bishop, Katherine S Button, Christopher D Chambers, Nathalie Percie Du Sert, Uri Simonsohn, Eric-Jan Wagenmakers, Jennifer J Ware, and John PA Ioannidis. 2017. “A Manifesto for Reproducible Science.” Nature Human Behaviour 1 (1): 1–9. Newman, George E, and Brian J Scholl. 2012. “Bar Graphs Depicting Averages Are Perceptually Misinterpreted: The Within-the-Bar Bias.” Psychonomic Bulletin &amp; Review 19 (4): 601–7. Robins, Anthony, Janet Rountree, and Nathan Rountree. 2003. “Learning and Teaching Programming: A Review and Discussion.” Computer Science Education 13 (2): 137–72. Visual, BBC, and Data Journalism. 2019. “How the BBC Visual and Data Journalism Team Works with Graphics in r.” Medium. https://medium.com/bbc-visual-and-data-journalism/how-the-bbc-visual-and-data-journalism-team-works-with-graphics-in-r-ed0b35693535. Wickham, Hadley. 2010. “A Layered Grammar of Graphics.” Journal of Computational and Graphical Statistics 19 (1): 3–28. ———. 2016. Ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York. https://ggplot2.tidyverse.org. ———. 2017. Tidyverse: Easily Install and Load the ’Tidyverse’. https://CRAN.R-project.org/package=tidyverse. Wickham, Hadley, and others. 2014. “Tidy Data.” Journal of Statistical Software 59 (10): 1–23. Wilkinson, Leland, Anushka Anand, and Robert Grossman. 2005. “Graph-Theoretic Scagnostics.” In IEEE Symposium on Information Visualization (InfoVis 05), 157–58. IEEE Computer Society. Wills, Andy. n.d. “Teaching Research Methods in r.” Rminr. https://www.andywills.info/rminr/rminrinpsy.html. "]
]
